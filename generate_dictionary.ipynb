{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad lines: 0\n"
     ]
    }
   ],
   "source": [
    "file_name = \"data/GloVe/glove.6B.50d.txt\"\n",
    "\n",
    "embedding = {}\n",
    "idx_to_word = {}\n",
    "word_to_idx = {}\n",
    "bad_lines = 0\n",
    "\n",
    "with open(file_name, 'r', encoding='UTF-8') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        try:\n",
    "            line = line.strip()\n",
    "            match_obj = re.match(r'([^\\s]+)', line)\n",
    "            word = match_obj.group(1)\n",
    "            word_len = len(word)\n",
    "            word_vec = line[word_len:].replace('\\n', '')\n",
    "\n",
    "            embed = word_vec.strip()\n",
    "            embed = embed.split()\n",
    "            embed = np.array(embed, dtype=np.float32)\n",
    "            \n",
    "            embedding[idx] = [embed]\n",
    "            idx_to_word[idx] = word.strip()\n",
    "            word_to_idx[word.strip()] = idx\n",
    "        except:\n",
    "            bad_lines += 1\n",
    "\n",
    "print(f'Bad lines: {bad_lines}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71814054]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'banana'\n",
    "w2 = 'fruit'\n",
    "\n",
    "w1_embed = embedding[word_to_idx[w1]]\n",
    "w2_embed = embedding[word_to_idx[w2]]\n",
    "cosine_similarity(w1_embed, w2_embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/opted/OPTED-Dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>POS</th>\n",
       "      <th>Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>\"The first letter of the English and of many o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>\"The name of the sixth tone in the model major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>\"An adjective  commonly called the indefinite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>\"In each; to or for each; as  \"\"\"\"twenty leagu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>\"prep.\"</td>\n",
       "      <td>\"In; on; at; by.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word Count      POS                                         Definition\n",
       "0    A     1       \"\"  \"The first letter of the English and of many o...\n",
       "1    A     1       \"\"  \"The name of the sixth tone in the model major...\n",
       "2    A     1       \"\"  \"An adjective  commonly called the indefinite ...\n",
       "3    A     1       \"\"  \"In each; to or for each; as  \"\"\"\"twenty leagu...\n",
       "4    A     1  \"prep.\"                                  \"In; on; at; by.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Word\"] = df[\"Word\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abate'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Word\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_remove = re.compile(r'[{}]'.format(re.escape(string.punctuation)))\n",
    "df[\"Definition\"] = df[\"Definition\"].map(lambda x: chars_to_remove.sub('', x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>POS</th>\n",
       "      <th>Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>the first letter of the english and of many ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>the name of the sixth tone in the model major ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>an adjective  commonly called the indefinite a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>in each to or for each as  twenty leagues a da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>\"prep.\"</td>\n",
       "      <td>in on at by</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word Count      POS                                         Definition\n",
       "0    a     1       \"\"  the first letter of the english and of many ot...\n",
       "1    a     1       \"\"  the name of the sixth tone in the model major ...\n",
       "2    a     1       \"\"  an adjective  commonly called the indefinite a...\n",
       "3    a     1       \"\"  in each to or for each as  twenty leagues a da...\n",
       "4    a     1  \"prep.\"                                        in on at by"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in each to or for each as  twenty leagues a day a hundred pounds a year a dollar a yard etc\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Definition\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176009, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Word\"].isin(word_to_idx.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102236, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Word\"] != \"\"]\n",
    "df = df[df[\"Definition\"] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102234, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 13:36:38.166267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-19 13:36:38.170620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-19 13:36:38.170952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-19 13:36:38.192101: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-19 13:36:38.193216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-19 13:36:38.194257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-19 13:36:38.194784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-19 13:36:38.467636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-19 13:36:38.468061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-19 13:36:38.468380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-19 13:36:38.468676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 102234\n"
     ]
    }
   ],
   "source": [
    "seq_length = 32\n",
    "\n",
    "def generate_sequences(dataset):\n",
    "    num_sequences = dataset.shape[0]\n",
    "\n",
    "    x_token = np.zeros((num_sequences, seq_length))\n",
    "    x_mask = np.zeros((num_sequences, seq_length))\n",
    "    y_token = np.zeros((num_sequences, 50), dtype=np.float64)\n",
    "\n",
    "    for i in range(0, num_sequences):\n",
    "        try:\n",
    "            word = dataset[\"Word\"].iloc[i]\n",
    "            definition = dataset[\"Definition\"].iloc[i]\n",
    "\n",
    "            tokens = tokenizer.tokenize(definition)\n",
    "            input = tokenizer.encode_plus(tokens, max_length=seq_length, truncation=True, padding='max_length', add_special_tokens=True, return_tensors='tf')\n",
    "            \n",
    "            x_token[i, :] = input['input_ids']\n",
    "            x_mask[i, :] = input['attention_mask']\n",
    "            y_token[i, :] = embedding[word_to_idx[word]][0]\n",
    "        \n",
    "        except:\n",
    "            print(f'Error on {i}')\n",
    "\n",
    "\n",
    "    print(f'Number of sequences: {num_sequences}')\n",
    "\n",
    "    return x_token, x_mask, y_token, num_sequences\n",
    "\n",
    "x_token, x_mask, y_token, num_sequences = generate_sequences(df[[\"Word\", \"Definition\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((32,), (32,), (50,)), types: (tf.float64, tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_token, x_mask, y_token))\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (32,), attention_mask: (32,)}, (50,)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_input_mask(input_id, mask, y_token):\n",
    "    return {'input_ids': input_id, 'attention_mask': mask}, y_token\n",
    "\n",
    "dataset = dataset.map(combine_input_mask)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (64, 32), attention_mask: (64, 32)}, (64, 50)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float64)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 13:37:56.620582: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 32)]         0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 32,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         787456      ['bert[0][1]']                   \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 1024)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 50)           51250       ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 110,320,946\n",
      "Trainable params: 838,706\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(seq_length,), name='input_ids', dtype=tf.int32)\n",
    "mask_layer = Input(shape=(seq_length,),\n",
    "                   name='attention_mask', dtype=tf.int32)\n",
    "\n",
    "embedding_layer = bert.bert(input_layer, attention_mask=mask_layer)[1]\n",
    "\n",
    "out = Dense(1024, activation='relu')(embedding_layer)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Dense(50)(out)\n",
    "\n",
    "model = Model(inputs=[input_layer, mask_layer], outputs=out)\n",
    "\n",
    "model.layers[2].trainable = False\n",
    "\n",
    "optimizer = SGD(learning_rate=0.00009, decay=1e-6)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.losses.mean_squared_error, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.0404WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 137s 84ms/step - loss: 0.5674 - accuracy: 0.0404\n",
      "Epoch 2/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4910 - accuracy: 0.0960WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 134s 84ms/step - loss: 0.4910 - accuracy: 0.0960\n",
      "Epoch 3/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.1160WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 135s 84ms/step - loss: 0.4801 - accuracy: 0.1160\n",
      "Epoch 4/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.1274WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4733 - accuracy: 0.1274\n",
      "Epoch 5/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4681 - accuracy: 0.1339WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4681 - accuracy: 0.1339\n",
      "Epoch 6/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.1398WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4636 - accuracy: 0.1398\n",
      "Epoch 7/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4600 - accuracy: 0.1437WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4600 - accuracy: 0.1437\n",
      "Epoch 8/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4566 - accuracy: 0.1494WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4566 - accuracy: 0.1494\n",
      "Epoch 9/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4535 - accuracy: 0.1540WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4535 - accuracy: 0.1540\n",
      "Epoch 10/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.1592WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4509 - accuracy: 0.1592\n",
      "Epoch 11/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4484 - accuracy: 0.1626WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4484 - accuracy: 0.1626\n",
      "Epoch 12/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.1690WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4459 - accuracy: 0.1690\n",
      "Epoch 13/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.1720WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4436 - accuracy: 0.1720\n",
      "Epoch 14/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.1758WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4415 - accuracy: 0.1758\n",
      "Epoch 15/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.1816WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4394 - accuracy: 0.1816\n",
      "Epoch 16/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.1837WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4377 - accuracy: 0.1837\n",
      "Epoch 17/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.1884WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4361 - accuracy: 0.1884\n",
      "Epoch 18/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.1926WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4344 - accuracy: 0.1926\n",
      "Epoch 19/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4329 - accuracy: 0.1956WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4329 - accuracy: 0.1956\n",
      "Epoch 20/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.1993WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4311 - accuracy: 0.1993\n",
      "Epoch 21/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.2030WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4298 - accuracy: 0.2030\n",
      "Epoch 22/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4284 - accuracy: 0.2070WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4284 - accuracy: 0.2070\n",
      "Epoch 23/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.2088WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4274 - accuracy: 0.2088\n",
      "Epoch 24/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4259 - accuracy: 0.2141WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4259 - accuracy: 0.2141\n",
      "Epoch 25/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4249 - accuracy: 0.2164WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4249 - accuracy: 0.2164\n",
      "Epoch 26/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4239 - accuracy: 0.2173WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4239 - accuracy: 0.2173\n",
      "Epoch 27/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.2209WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4229 - accuracy: 0.2209\n",
      "Epoch 28/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4219 - accuracy: 0.2239WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4219 - accuracy: 0.2239\n",
      "Epoch 29/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.2255WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4209 - accuracy: 0.2255\n",
      "Epoch 30/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4200 - accuracy: 0.2278WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4200 - accuracy: 0.2278\n",
      "Epoch 31/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4193 - accuracy: 0.2300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4193 - accuracy: 0.2300\n",
      "Epoch 32/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.2328WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4184 - accuracy: 0.2328\n",
      "Epoch 33/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 0.2348WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4177 - accuracy: 0.2348\n",
      "Epoch 34/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.2358WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4170 - accuracy: 0.2358\n",
      "Epoch 35/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4162 - accuracy: 0.2381WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4162 - accuracy: 0.2381\n",
      "Epoch 36/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4154 - accuracy: 0.2399WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4154 - accuracy: 0.2399\n",
      "Epoch 37/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.2413WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4148 - accuracy: 0.2413\n",
      "Epoch 38/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4142 - accuracy: 0.2437WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4142 - accuracy: 0.2437\n",
      "Epoch 39/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4137 - accuracy: 0.2437WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4137 - accuracy: 0.2437\n",
      "Epoch 40/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4133 - accuracy: 0.2451WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4133 - accuracy: 0.2451\n",
      "Epoch 41/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4125 - accuracy: 0.2470WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4125 - accuracy: 0.2470\n",
      "Epoch 42/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4121 - accuracy: 0.2488WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4121 - accuracy: 0.2488\n",
      "Epoch 43/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.2492WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4115 - accuracy: 0.2492\n",
      "Epoch 44/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4111 - accuracy: 0.2509WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4111 - accuracy: 0.2509\n",
      "Epoch 45/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4107 - accuracy: 0.2505WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4107 - accuracy: 0.2505\n",
      "Epoch 46/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4103 - accuracy: 0.2524WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4103 - accuracy: 0.2524\n",
      "Epoch 47/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.2536WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4099 - accuracy: 0.2536\n",
      "Epoch 48/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4095 - accuracy: 0.2541WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4095 - accuracy: 0.2541\n",
      "Epoch 49/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.2549WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4091 - accuracy: 0.2549\n",
      "Epoch 50/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4087 - accuracy: 0.2554WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4087 - accuracy: 0.2554\n",
      "Epoch 51/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.2555WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4083 - accuracy: 0.2555\n",
      "Epoch 52/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.2560WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 108s 68ms/step - loss: 0.4081 - accuracy: 0.2560\n",
      "Epoch 53/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.2583WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 109s 68ms/step - loss: 0.4077 - accuracy: 0.2583\n",
      "Epoch 54/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.2586WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 118s 74ms/step - loss: 0.4074 - accuracy: 0.2586\n",
      "Epoch 55/100\n",
      "1597/1597 [==============================] - ETA: 0s - loss: 0.4069 - accuracy: 0.2595WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1597/1597 [==============================] - 119s 75ms/step - loss: 0.4069 - accuracy: 0.2595\n",
      "Epoch 56/100\n",
      " 903/1597 [===============>..............] - ETA: 52s - loss: 0.4070 - accuracy: 0.2513"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_131626/4279110476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      mode='min', save_best_only=True, verbose=1)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m history = model.fit(dataset, batch_size=64, epochs=100,\n\u001b[0m\u001b[1;32m      6\u001b[0m                     shuffle=True, verbose=1, callbacks=[es, mc])\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint('reverse_model_whole.h5', monitor='val_loss',\n",
    "                     mode='min', save_best_only=True, verbose=1)\n",
    "\n",
    "history = model.fit(dataset, batch_size=64, epochs=100,\n",
    "                    shuffle=True, verbose=1, callbacks=[es, mc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3ecfbb2e518759e8150e3a4e02d9374d8d11351137435699613669ebcf0f527"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
